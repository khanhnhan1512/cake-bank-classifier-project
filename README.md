# Liveness Detection System (Section 1)

## 1. Project Overview
This project develops an AI model to distinguish between **Real faces (Live)** and **Spoofed faces (Fake)** using Deep Learning. The goal is to enhance security in eKYC systems by detecting attacks such as printed photos, screen replays, or masks.

- **Input:** RGB Images.
- **Output:** Liveness Score [0, 1] (0 = Real, 1 = Spoof).
- **Environment:** Managed by `uv` (Modern Python package manager).

## 2. System Specifications
The development and training were conducted on the following hardware:
- **OS:** Windows 10/11
- **CPU:** (Standard Desktop CPU)
- **RAM:** 16GB
- **GPU:** NVIDIA GeForce RTX 3070Ti (8GB VRAM)
- **Python Version:** 3.10+

## 3. Workflow & Rationale (Methodology)

Our approach follows a strict Data Engineering & ML pipeline:

### Step 1: Exploratory Data Analysis (EDA)
Before any modeling, we analyzed the dataset distribution in `notebooks/check_quality.ipynb`.
- **Action:** Checked for class imbalance between "Normal" and "Spoof" samples.
- **Rationale:** Understanding class distribution determines the choice of Loss Function. Since the dataset was relatively balanced, we opted for **CrossEntropyLoss** to ensure faster convergence without bias.

### Step 2: Data Preprocessing (Crucial Improvement)
We implemented a custom pipeline in `src/classifier/preprocess.py`.
- **Face Detection:** We utilized **Google MediaPipe Face Detection**. MediaPipe is especially robust for faces with occlusions (masks), extreme angles, or varying lighting conditions, ensuring high-quality input for the model.
- **Scale Strategy (The "Secret Sauce"):** Instead of tight face cropping, we used a **Scale Factor of 1.6**. Initial experiments with tight crops (Scale 1.3) yielded lower Recall (~87%). Expanding the crop (Scale 1.6) allows the model to see **context clues**. This simple change boosted Recall to **~97%**.

### Step 3: Model Architecture
We selected **EfficientNet-B2** with Transfer Learning (ImageNet weights).
- **Rationale:** EfficientNet-B2 offers an optimal balance between **Accuracy** and **Inference Latency**. It is significantly lighter than ResNet50 but provides deeper feature extraction than MobileNet, making it suitable for potential edge deployment in banking apps.

### Step 4: Training Strategy
- **Optimizer:** Adam (LR=1e-3) with CosineAnnealing Scheduler.
- **Regularization:**
    - `Weight Decay (1e-4)`: Added to penalize large weights and reduce overfitting.
    - `Dropout (p=0.3)`: Applied in the classifier head.
    - `EarlyStopping`: Monitors Validation Loss to stop training at the optimal point.
- **Metric Focus:** We prioritize **Recall** (catching spoof attacks) over Precision, as missing a spoofer is a security risk.

## 4. Project Structure
```text
cake-bank-classifier-project/
├── data/                       # Data storage
│   ├── raw/                    # Original dataset
│   └── processed/              # Cropped & aligned faces (generated by preprocess.py)
├── notebooks/
│   ├── check_quality.ipynb     # EDA & Data check
├── models/
│   ├── best_model.pth          # Saved best model weights
├── src/
│   └── classifier/
│       ├── data_module/        # Dataset & Dataloader logic
│       ├── model.py            # EfficientNet-B2 architecture definition
│       ├── preprocess.py       # Face detection (MediaPipe) & cropping pipeline
│       ├── train.py            # Main training script (with MLflow tracking removed)
│       ├── predict.py          # Inference script for single image demo
│       ├── evaluations.py      # Metric calculation (F1, AUC, Recall...)
│       └── regularizations.py  # EarlyStopping logic
├── pyproject.toml              # Dependencies managed by uv
├── uv.lock                     # Lock file for reproducible builds
├── .python-version             # Python version specification
└── README.md                   # Project documentation
```

## 5. Results
The model was evaluated on the held-out Test Set (Processed):
| Metric | Value |
| :--- | :--- |
| **CrossEntropy Loss** | 0.2058 |
| **Accuracy** | 91.88% |
| **Recall (Spoof)** | **96.93%** |
| **Precision** | 87.70% |
| **ROC-AUC** | **0.9787** |
| **F1-Score** | 0.9208 |

=> Conclusion: The high Recall (~97%) and ROC-AUC (~0.98) demonstrate that the model is highly effective for security contexts, successfully catching the vast majority of spoofing attempts.

## Setup & Execution Guide
This project uses `uv` for extremely fast and reliable package management.

#### Prequisites:
- Install `uv`.
- Python 3.10+ environment.
#### Steps:
Step 1: Open terminal in project root directory and synchronize dependencies:
```
uv sync
```
Step 2: Activate the environment:
```
.venv\Scripts\activate
```
Step 3: Data Preprocessing

You must run this step first to generate the data/processed folder.
```
python src/classifier/preprocess.py
```
Step 4: Train the model
```
python src/classifier/train.py
```
Step 5: Inference on a single image
```
python src/classifier/predict.py --image path/to/your/image.jpg
```
